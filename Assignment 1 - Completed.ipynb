{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Assignment 1: Data Preprocessing and Exploratory Data Analysis - COMPLETED\n",
    "\n",
    "**Student Name:** Samson Silver  \n",
    "**Student ID:** 815337747  \n",
    "**Points:** 10 (8 points for Assignment + 2 points for survey)\n",
    "\n",
    "## Assignment Overview\n",
    "This completed notebook works with the \"Salary Survey\" dataset, which contains salary information and workplace characteristics from thousands of respondents. This dataset presents typical challenges found in real-world data science projects.\n",
    "\n",
    "## Dataset Information\n",
    "- **File:** `salary_survey.csv`\n",
    "- **Content:** Salary information and workplace characteristics\n",
    "- **Size:** 27,940 records with 18 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "Import all necessary libraries for data analysis, visualization, and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Try to import missingno with graceful fallback\n",
    "try:\n",
    "    import missingno as msno\n",
    "    MISSINGNO_AVAILABLE = True\n",
    "    print(\"missingno package imported successfully\")\n",
    "except ImportError:\n",
    "    MISSINGNO_AVAILABLE = False\n",
    "    print(\"missingno package not available, using seaborn/matplotlib alternatives\")\n",
    "\n",
    "# Optional: scikit-learn for future modeling\n",
    "try:\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"scikit-learn imported successfully\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"scikit-learn not available\")\n",
    "\n",
    "# Set plotting style and random seed\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"All libraries imported and configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1_header",
   "metadata": {},
   "source": [
    "# Task 1: Data Description and Exploration (2 Points)\n",
    "\n",
    "## 1.1 Dataset Overview\n",
    "**Instructions:** \n",
    "- Load the dataset from the CSV file `salary_survey.csv`\n",
    "- Display basic statistics (shape, columns, data types)\n",
    "- Create a comprehensive data dictionary explaining each variable\n",
    "- Identify potential target variable(s) for future modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('salary_survey.csv')\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv('salary_survey.csv', encoding='latin-1')\n",
    "    print(\"Dataset loaded with latin-1 encoding\")\n",
    "\n",
    "# Store original data\n",
    "df_original = df.copy()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]:,}, Columns: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info and statistics\n",
    "print(\"=== DATASET INFO ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic data dictionary analysis\n",
    "print(\"=== DATA DICTIONARY ANALYSIS ===\")\n",
    "\n",
    "data_dict = []\n",
    "for col in df.columns:\n",
    "    col_info = {\n",
    "        'Column': col[:50] + '...' if len(col) > 50 else col,\n",
    "        'Data_Type': str(df[col].dtype),\n",
    "        'Non_Null': df[col].count(),\n",
    "        'Null_Count': df[col].isnull().sum(),\n",
    "        'Null_Pct': round(df[col].isnull().mean() * 100, 1),\n",
    "        'Unique': df[col].nunique()\n",
    "    }\n",
    "    \n",
    "    # Infer type\n",
    "    if df[col].dtype in ['int64', 'float64']:\n",
    "        col_info['Type'] = 'Numeric'\n",
    "    elif df[col].nunique() / len(df) < 0.05:\n",
    "        col_info['Type'] = 'Categorical'\n",
    "    else:\n",
    "        col_info['Type'] = 'Free_Text'\n",
    "        \n",
    "    data_dict.append(col_info)\n",
    "\n",
    "dict_df = pd.DataFrame(data_dict)\n",
    "display(dict_df)\n",
    "\n",
    "# Sample values for key columns\n",
    "key_cols = ['How old are you?', 'What industry do you work in?', \n",
    "           'Please indicate the currency', 'What country do you work in?']\n",
    "\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {df[col].nunique()}\")\n",
    "        if df[col].nunique() <= 15:\n",
    "            print(\"  Value counts:\")\n",
    "            print(df[col].value_counts().head(10))\n",
    "        else:\n",
    "            print(f\"  Sample values: {list(df[col].dropna().unique()[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_dictionary_markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Data Dictionary\n",
    "\n",
    "Based on the analysis above:\n",
    "\n",
    "### **Survey Metadata**\n",
    "- **Timestamp**: Survey submission date/time (MM/DD/YYYY HH:MM:SS)\n",
    "\n",
    "### **Demographics**\n",
    "- **How old are you?**: Age groups (25-34, 35-44, etc.)\n",
    "- **What is your gender?**: Gender identity categories\n",
    "- **What is your race?**: Racial/ethnic identity (multiple selections)\n",
    "\n",
    "### **Employment**\n",
    "- **What industry do you work in?**: Industry categories\n",
    "- **Job title**: Free-text job titles\n",
    "- **Job title context**: Optional clarification\n",
    "\n",
    "### **Compensation (TARGET VARIABLES)**\n",
    "- **Annual salary**: Primary target - yearly salary (string format with commas)\n",
    "- **Additional compensation**: Bonuses, overtime, etc.\n",
    "- **Currency**: Currency codes (USD, GBP, EUR, etc.)\n",
    "- **Other currency**: Free-text currency specification\n",
    "- **Income context**: Optional income clarification\n",
    "\n",
    "### **Experience & Education**\n",
    "- **Overall experience**: Total work experience ranges\n",
    "- **Field experience**: Experience in current field\n",
    "- **Education level**: Highest education completed\n",
    "\n",
    "### **Location**\n",
    "- **Country**: Work country\n",
    "- **US State**: US state (if applicable)\n",
    "- **City**: Work city\n",
    "\n",
    "### **Target Variables for Modeling**\n",
    "1. **Primary**: Annual salary (after cleaning)\n",
    "2. **Secondary**: Total compensation (salary + additional)\n",
    "3. **Alternative**: Salary categories/bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_1_1",
   "metadata": {},
   "source": [
    "### ðŸ“Š Your Analysis (Task 1.1)\n",
    "\n",
    "The salary survey dataset contains **27,940 responses** across **18 columns**, representing a substantial sample for compensation analysis. Key observations:\n",
    "\n",
    "**Data Quality Overview:**\n",
    "- Most demographic and employment fields have complete data\n",
    "- Optional fields show expected higher missingness\n",
    "- Multi-country, multi-currency dataset requiring normalization\n",
    "\n",
    "**Key Patterns:**\n",
    "1. **Demographics**: Concentration in 25-34 age group suggests tech/professional sample\n",
    "2. **Industries**: Computing/Tech heavily represented\n",
    "3. **Geography**: Primarily English-speaking countries\n",
    "4. **Salary Format**: Requires cleaning (commas, string format)\n",
    "\n",
    "**Modeling Potential**: Excellent for salary prediction with clear predictors (demographics, experience, location, industry) and targets (salary, total compensation).\n",
    "\n",
    "**Collection Context**: Online survey likely distributed through professional networks, explaining demographic skew toward tech professionals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai_analysis_1_1",
   "metadata": {},
   "source": [
    "### ðŸ¤– AI-Assisted Analysis (Task 1.1)\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "\n",
    "This salary survey represents modern crowdsourced compensation data with notable features:\n",
    "\n",
    "**Strengths:**\n",
    "- **Large Sample**: 27,940+ responses provide strong statistical power\n",
    "- **Comprehensive Coverage**: Captures key salary determinants\n",
    "- **International Scope**: Multi-currency analysis capabilities\n",
    "- **Experience Granularity**: Overall vs. field-specific experience tracking\n",
    "\n",
    "**Potential Challenges:**\n",
    "1. **Selection Bias**: Tech professional skew from distribution channels\n",
    "2. **Self-Reporting**: Accuracy depends on respondent honesty\n",
    "3. **Currency/PPP**: Cross-country comparisons need adjustment\n",
    "4. **Temporal Variation**: Responses span different economic periods\n",
    "\n",
    "**Investigation Strategies:**\n",
    "- Analyze temporal patterns in responses\n",
    "- Examine outliers for data entry errors\n",
    "- Cross-validate demographics against census data\n",
    "- Investigate systematic missing data patterns\n",
    "\n",
    "**Industry Context**: Reflects salary transparency trends in tech/professional sectors, enabling compensation equity analysis across demographics and regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1_2_header",
   "metadata": {},
   "source": [
    "## 1.2 Initial Data Quality Assessment\n",
    "**Instructions:**\n",
    "- Calculate missing value percentages and create visualizations\n",
    "- Identify formatting issues in numeric and categorical fields\n",
    "- Detect outliers using statistical methods\n",
    "- Assess data collection issues and their implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"=== MISSING VALUES ANALYSIS ===\")\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': round(df.isnull().mean() * 100, 2),\n",
    "    'Data_Type': df.dtypes\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing value summary:\")\n",
    "display(missing_stats)\n",
    "\n",
    "# Visualization of missing values\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Bar chart of missing percentages\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "missing_pct_sorted = missing_pct.sort_values(ascending=True)\n",
    "axes[0].barh(range(len(missing_pct_sorted)), missing_pct_sorted.values)\n",
    "axes[0].set_yticks(range(len(missing_pct_sorted)))\n",
    "axes[0].set_yticklabels([col[:30] + '...' if len(col) > 30 else col for col in missing_pct_sorted.index])\n",
    "axes[0].set_xlabel('Missing Percentage (%)')\n",
    "axes[0].set_title('Missing Values by Column')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Missingness heatmap (alternative to missingno)\n",
    "if MISSINGNO_AVAILABLE:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    msno.matrix(df)\n",
    "    plt.title('Missingness Pattern Matrix')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Alternative heatmap using seaborn\n",
    "    missing_data = df.isnull()\n",
    "    sns.heatmap(missing_data.T, cbar=True, yticklabels=True, \n",
    "                cmap='viridis', ax=axes[1])\n",
    "    axes[1].set_title('Missing Data Pattern (Yellow = Missing)')\n",
    "    axes[1].set_xlabel('Row Index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}